{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZYezk4ifjMt",
        "outputId": "5eb9bbce-c679-470b-f3a9-f2cb50f32331"
      },
      "outputs": [],
      "source": [
        "#pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbO28lIOflSH",
        "outputId": "52d65b01-784c-41de-a3c4-ef995f37e590"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\koyama\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 加载数据\n",
        "data_full = pd.read_excel('C:/1作品/clothse_excel/train1641.xlsx')\n",
        "\n",
        "# 填充缺失值\n",
        "data_full['max_tem'].fillna(data_full['max_tem'].mean(), inplace=True)\n",
        "data_full['sensible_temperature'].fillna(data_full['sensible_temperature'].mean(), inplace=True)\n",
        "data_full['label1'].fillna('nothing', inplace=True)\n",
        "data_full['label2'].fillna('nothing', inplace=True)\n",
        "# 假设label3没有缺失值\n",
        "\n",
        "# 特征和标签\n",
        "features = data_full[['max_tem', 'min_tem', 'mean_tem', 'average_humidity(％)', 'average_wind_speed(m/s)', 'sensible_temperature']]\n",
        "labels = data_full[['label1', 'label2', 'label3']]\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "\n",
        "# 编码标签\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "labels_encoded = encoder.fit_transform(labels)\n",
        "\n",
        "# 分割数据为训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_standardized, labels_encoded, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFREuzB1fy-u",
        "outputId": "df4080a1-d9fc-4813-8f96-3a6e32e7cb9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-03 18:45:35,680] A new study created in memory with name: no-name-69b7a7f9-72b1-4cc9-b6b1-516106dd8c77\n",
            "[I 2024-02-03 18:45:38,821] Trial 0 finished with value: 0.2974013686180115 and parameters: {'num_layers': 3, 'dropout_rate': 0.4247791971802093, 'learning_rate': 6.201203456724875e-05, 'num_hidden_0': 142, 'num_hidden_1': 43, 'num_hidden_2': 184}. Best is trial 0 with value: 0.2974013686180115.\n",
            "[I 2024-02-03 18:45:41,515] Trial 1 finished with value: 0.1531328409910202 and parameters: {'num_layers': 1, 'dropout_rate': 0.1619855070806956, 'learning_rate': 0.018740258673417977, 'num_hidden_0': 159}. Best is trial 1 with value: 0.1531328409910202.\n",
            "[I 2024-02-03 18:45:43,497] Trial 2 finished with value: 0.14888179302215576 and parameters: {'num_layers': 1, 'dropout_rate': 0.30307550914661086, 'learning_rate': 0.013651366116021269, 'num_hidden_0': 135}. Best is trial 2 with value: 0.14888179302215576.\n",
            "[I 2024-02-03 18:45:46,270] Trial 3 finished with value: 0.14961135387420654 and parameters: {'num_layers': 3, 'dropout_rate': 0.4720999589648879, 'learning_rate': 0.0009786564648323907, 'num_hidden_0': 104, 'num_hidden_1': 200, 'num_hidden_2': 144}. Best is trial 2 with value: 0.14888179302215576.\n",
            "[I 2024-02-03 18:45:48,625] Trial 4 finished with value: 0.15411224961280823 and parameters: {'num_layers': 1, 'dropout_rate': 0.08683263205866104, 'learning_rate': 0.030044557132939367, 'num_hidden_0': 40}. Best is trial 2 with value: 0.14888179302215576.\n",
            "[I 2024-02-03 18:45:50,976] Trial 5 finished with value: 0.15147517621517181 and parameters: {'num_layers': 1, 'dropout_rate': 0.3222271969157633, 'learning_rate': 0.0055538182714492765, 'num_hidden_0': 99}. Best is trial 2 with value: 0.14888179302215576.\n",
            "[I 2024-02-03 18:45:53,345] Trial 6 finished with value: 0.1670023500919342 and parameters: {'num_layers': 2, 'dropout_rate': 0.01956048104153335, 'learning_rate': 0.0006915823325650894, 'num_hidden_0': 10, 'num_hidden_1': 76}. Best is trial 2 with value: 0.14888179302215576.\n",
            "[I 2024-02-03 18:45:55,953] Trial 7 finished with value: 0.15941676497459412 and parameters: {'num_layers': 3, 'dropout_rate': 0.4888705288993377, 'learning_rate': 0.02661673549746258, 'num_hidden_0': 138, 'num_hidden_1': 162, 'num_hidden_2': 40}. Best is trial 2 with value: 0.14888179302215576.\n",
            "[I 2024-02-03 18:45:58,676] Trial 8 finished with value: 0.14740563929080963 and parameters: {'num_layers': 2, 'dropout_rate': 0.09196756340622869, 'learning_rate': 0.04305435574471603, 'num_hidden_0': 55, 'num_hidden_1': 24}. Best is trial 8 with value: 0.14740563929080963.\n",
            "[I 2024-02-03 18:46:02,368] Trial 9 finished with value: 0.15679924190044403 and parameters: {'num_layers': 1, 'dropout_rate': 0.38962033102385196, 'learning_rate': 0.008994623790111182, 'num_hidden_0': 139}. Best is trial 8 with value: 0.14740563929080963.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials: 10\n",
            "Best trial: {'num_layers': 2, 'dropout_rate': 0.09196756340622869, 'learning_rate': 0.04305435574471603, 'num_hidden_0': 55, 'num_hidden_1': 24}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# 假设 X_train, y_train 是您的训练数据和标签\n",
        "# X_train, y_train = ...\n",
        "\n",
        "def create_model(trial):\n",
        "    # 为模型的各个超参数定义搜索空间\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    # 添加隐藏层\n",
        "    for i in range(num_layers):\n",
        "        num_hidden = trial.suggest_int(f'num_hidden_{i}', 10, 200)\n",
        "        model.add(keras.layers.Dense(num_hidden, activation='relu'))\n",
        "        model.add(keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(keras.layers.Dense(y_train.shape[1], activation='sigmoid'))\n",
        "\n",
        "    # 编译模型\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def objective(trial):\n",
        "    # 创建模型\n",
        "    model = create_model(trial)\n",
        "\n",
        "    # 分割数据为训练集和验证集\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(X_train_split, y_train_split, epochs=10, validation_data=(X_val_split, y_val_split), verbose=0)\n",
        "\n",
        "    # 在验证集上评估模型性能\n",
        "    loss, accuracy = model.evaluate(X_val_split, y_val_split, verbose=0)\n",
        "\n",
        "    # 由于Optuna最小化目标函数，因此返回损失\n",
        "    return loss\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10) # 可以调整 n_trials 来控制尝试的超参数组合数\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VJ07R-HhMtL",
        "outputId": "979a7e34-aaf1-41a0-b705-326e140d68d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "33/33 - 1s - loss: 0.2393 - accuracy: 0.3184 - val_loss: 0.1662 - val_accuracy: 0.3308 - 1s/epoch - 45ms/step\n",
            "Epoch 2/100\n",
            "33/33 - 0s - loss: 0.1579 - accuracy: 0.3680 - val_loss: 0.1588 - val_accuracy: 0.3308 - 92ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "33/33 - 0s - loss: 0.1548 - accuracy: 0.3889 - val_loss: 0.1574 - val_accuracy: 0.3726 - 79ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "33/33 - 0s - loss: 0.1528 - accuracy: 0.3708 - val_loss: 0.1574 - val_accuracy: 0.3726 - 100ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "33/33 - 0s - loss: 0.1517 - accuracy: 0.3556 - val_loss: 0.1584 - val_accuracy: 0.3346 - 88ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "33/33 - 0s - loss: 0.1511 - accuracy: 0.3584 - val_loss: 0.1587 - val_accuracy: 0.3612 - 126ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "33/33 - 0s - loss: 0.1495 - accuracy: 0.3670 - val_loss: 0.1557 - val_accuracy: 0.3004 - 115ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "33/33 - 0s - loss: 0.1486 - accuracy: 0.3422 - val_loss: 0.1554 - val_accuracy: 0.2814 - 117ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "33/33 - 0s - loss: 0.1488 - accuracy: 0.3556 - val_loss: 0.1561 - val_accuracy: 0.2814 - 117ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "33/33 - 0s - loss: 0.1491 - accuracy: 0.3489 - val_loss: 0.1537 - val_accuracy: 0.3004 - 123ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "33/33 - 0s - loss: 0.1473 - accuracy: 0.3765 - val_loss: 0.1552 - val_accuracy: 0.3232 - 122ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "33/33 - 0s - loss: 0.1471 - accuracy: 0.3346 - val_loss: 0.1541 - val_accuracy: 0.3194 - 109ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "33/33 - 0s - loss: 0.1470 - accuracy: 0.3642 - val_loss: 0.1541 - val_accuracy: 0.2814 - 125ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "33/33 - 0s - loss: 0.1465 - accuracy: 0.3603 - val_loss: 0.1551 - val_accuracy: 0.3840 - 108ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "33/33 - 0s - loss: 0.1469 - accuracy: 0.3384 - val_loss: 0.1542 - val_accuracy: 0.3156 - 104ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "33/33 - 0s - loss: 0.1461 - accuracy: 0.3785 - val_loss: 0.1526 - val_accuracy: 0.3422 - 98ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "33/33 - 0s - loss: 0.1454 - accuracy: 0.3785 - val_loss: 0.1552 - val_accuracy: 0.3688 - 117ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "33/33 - 0s - loss: 0.1453 - accuracy: 0.3832 - val_loss: 0.1548 - val_accuracy: 0.3384 - 109ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "33/33 - 0s - loss: 0.1457 - accuracy: 0.3765 - val_loss: 0.1547 - val_accuracy: 0.3042 - 118ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "33/33 - 0s - loss: 0.1452 - accuracy: 0.3651 - val_loss: 0.1547 - val_accuracy: 0.3194 - 123ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "33/33 - 0s - loss: 0.1451 - accuracy: 0.3632 - val_loss: 0.1558 - val_accuracy: 0.3688 - 88ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "33/33 - 0s - loss: 0.1455 - accuracy: 0.3651 - val_loss: 0.1531 - val_accuracy: 0.3232 - 98ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "33/33 - 0s - loss: 0.1450 - accuracy: 0.3842 - val_loss: 0.1530 - val_accuracy: 0.4030 - 92ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "33/33 - 0s - loss: 0.1445 - accuracy: 0.3508 - val_loss: 0.1528 - val_accuracy: 0.3574 - 125ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "33/33 - 0s - loss: 0.1439 - accuracy: 0.3804 - val_loss: 0.1523 - val_accuracy: 0.3004 - 104ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "33/33 - 0s - loss: 0.1433 - accuracy: 0.3889 - val_loss: 0.1529 - val_accuracy: 0.3384 - 121ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "33/33 - 0s - loss: 0.1446 - accuracy: 0.3737 - val_loss: 0.1528 - val_accuracy: 0.3422 - 108ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "33/33 - 0s - loss: 0.1447 - accuracy: 0.3718 - val_loss: 0.1530 - val_accuracy: 0.3270 - 120ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "33/33 - 0s - loss: 0.1436 - accuracy: 0.3880 - val_loss: 0.1511 - val_accuracy: 0.3004 - 109ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "33/33 - 0s - loss: 0.1434 - accuracy: 0.3308 - val_loss: 0.1535 - val_accuracy: 0.3156 - 118ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "33/33 - 0s - loss: 0.1446 - accuracy: 0.3632 - val_loss: 0.1523 - val_accuracy: 0.3840 - 96ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "33/33 - 0s - loss: 0.1443 - accuracy: 0.4204 - val_loss: 0.1529 - val_accuracy: 0.3118 - 131ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "33/33 - 0s - loss: 0.1442 - accuracy: 0.3956 - val_loss: 0.1535 - val_accuracy: 0.3574 - 117ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "33/33 - 0s - loss: 0.1439 - accuracy: 0.3689 - val_loss: 0.1513 - val_accuracy: 0.3498 - 97ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "33/33 - 0s - loss: 0.1427 - accuracy: 0.3861 - val_loss: 0.1522 - val_accuracy: 0.3498 - 118ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "33/33 - 0s - loss: 0.1422 - accuracy: 0.3785 - val_loss: 0.1517 - val_accuracy: 0.2928 - 105ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "33/33 - 0s - loss: 0.1434 - accuracy: 0.4013 - val_loss: 0.1516 - val_accuracy: 0.3346 - 112ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "33/33 - 0s - loss: 0.1429 - accuracy: 0.3632 - val_loss: 0.1514 - val_accuracy: 0.3384 - 93ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "33/33 - 0s - loss: 0.1436 - accuracy: 0.3851 - val_loss: 0.1530 - val_accuracy: 0.3688 - 94ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "33/33 - 0s - loss: 0.1436 - accuracy: 0.3842 - val_loss: 0.1529 - val_accuracy: 0.3194 - 97ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "33/33 - 0s - loss: 0.1435 - accuracy: 0.4071 - val_loss: 0.1516 - val_accuracy: 0.3422 - 85ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "33/33 - 0s - loss: 0.1420 - accuracy: 0.3842 - val_loss: 0.1516 - val_accuracy: 0.3536 - 110ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "33/33 - 0s - loss: 0.1428 - accuracy: 0.3499 - val_loss: 0.1516 - val_accuracy: 0.3346 - 109ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "33/33 - 0s - loss: 0.1429 - accuracy: 0.3785 - val_loss: 0.1516 - val_accuracy: 0.3156 - 110ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "33/33 - 0s - loss: 0.1422 - accuracy: 0.3956 - val_loss: 0.1521 - val_accuracy: 0.2966 - 126ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "33/33 - 0s - loss: 0.1424 - accuracy: 0.3708 - val_loss: 0.1510 - val_accuracy: 0.3156 - 112ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "33/33 - 0s - loss: 0.1425 - accuracy: 0.3918 - val_loss: 0.1530 - val_accuracy: 0.3460 - 121ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "33/33 - 0s - loss: 0.1428 - accuracy: 0.3708 - val_loss: 0.1523 - val_accuracy: 0.3498 - 96ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "33/33 - 0s - loss: 0.1421 - accuracy: 0.3804 - val_loss: 0.1526 - val_accuracy: 0.3422 - 125ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "33/33 - 0s - loss: 0.1418 - accuracy: 0.4023 - val_loss: 0.1511 - val_accuracy: 0.3384 - 127ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "33/33 - 0s - loss: 0.1430 - accuracy: 0.3785 - val_loss: 0.1504 - val_accuracy: 0.3878 - 95ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "33/33 - 0s - loss: 0.1427 - accuracy: 0.3756 - val_loss: 0.1507 - val_accuracy: 0.3802 - 110ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "33/33 - 0s - loss: 0.1423 - accuracy: 0.3785 - val_loss: 0.1509 - val_accuracy: 0.3384 - 110ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "33/33 - 0s - loss: 0.1416 - accuracy: 0.4090 - val_loss: 0.1497 - val_accuracy: 0.3422 - 111ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "33/33 - 0s - loss: 0.1417 - accuracy: 0.3613 - val_loss: 0.1509 - val_accuracy: 0.3726 - 110ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "33/33 - 0s - loss: 0.1418 - accuracy: 0.3899 - val_loss: 0.1501 - val_accuracy: 0.3764 - 88ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "33/33 - 0s - loss: 0.1414 - accuracy: 0.3613 - val_loss: 0.1518 - val_accuracy: 0.3536 - 84ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "33/33 - 0s - loss: 0.1417 - accuracy: 0.3765 - val_loss: 0.1526 - val_accuracy: 0.2510 - 79ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "33/33 - 0s - loss: 0.1420 - accuracy: 0.3680 - val_loss: 0.1523 - val_accuracy: 0.3954 - 86ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "33/33 - 0s - loss: 0.1417 - accuracy: 0.3594 - val_loss: 0.1512 - val_accuracy: 0.3346 - 95ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "33/33 - 0s - loss: 0.1420 - accuracy: 0.3870 - val_loss: 0.1513 - val_accuracy: 0.3688 - 117ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "33/33 - 0s - loss: 0.1417 - accuracy: 0.3861 - val_loss: 0.1505 - val_accuracy: 0.3004 - 95ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "33/33 - 0s - loss: 0.1415 - accuracy: 0.3727 - val_loss: 0.1506 - val_accuracy: 0.3346 - 126ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "33/33 - 0s - loss: 0.1417 - accuracy: 0.3632 - val_loss: 0.1498 - val_accuracy: 0.3384 - 95ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "33/33 - 0s - loss: 0.1409 - accuracy: 0.3765 - val_loss: 0.1521 - val_accuracy: 0.3346 - 94ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "33/33 - 0s - loss: 0.1434 - accuracy: 0.3489 - val_loss: 0.1506 - val_accuracy: 0.3612 - 94ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "33/33 - 0s - loss: 0.1414 - accuracy: 0.3651 - val_loss: 0.1534 - val_accuracy: 0.3612 - 125ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "33/33 - 0s - loss: 0.1419 - accuracy: 0.3718 - val_loss: 0.1507 - val_accuracy: 0.3384 - 97ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "33/33 - 0s - loss: 0.1412 - accuracy: 0.3556 - val_loss: 0.1506 - val_accuracy: 0.3726 - 100ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "33/33 - 0s - loss: 0.1416 - accuracy: 0.3880 - val_loss: 0.1517 - val_accuracy: 0.3004 - 115ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "33/33 - 0s - loss: 0.1408 - accuracy: 0.3889 - val_loss: 0.1515 - val_accuracy: 0.3156 - 116ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "33/33 - 0s - loss: 0.1412 - accuracy: 0.3499 - val_loss: 0.1514 - val_accuracy: 0.3308 - 110ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "33/33 - 0s - loss: 0.1424 - accuracy: 0.3842 - val_loss: 0.1512 - val_accuracy: 0.3270 - 109ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "33/33 - 0s - loss: 0.1414 - accuracy: 0.3880 - val_loss: 0.1518 - val_accuracy: 0.3422 - 115ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "33/33 - 0s - loss: 0.1412 - accuracy: 0.3565 - val_loss: 0.1517 - val_accuracy: 0.3308 - 75ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "33/33 - 0s - loss: 0.1422 - accuracy: 0.3947 - val_loss: 0.1523 - val_accuracy: 0.3004 - 90ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "33/33 - 0s - loss: 0.1419 - accuracy: 0.3537 - val_loss: 0.1511 - val_accuracy: 0.3156 - 80ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "33/33 - 0s - loss: 0.1419 - accuracy: 0.3737 - val_loss: 0.1529 - val_accuracy: 0.3726 - 94ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "33/33 - 0s - loss: 0.1411 - accuracy: 0.3947 - val_loss: 0.1513 - val_accuracy: 0.3232 - 86ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "33/33 - 0s - loss: 0.1415 - accuracy: 0.3651 - val_loss: 0.1531 - val_accuracy: 0.3574 - 110ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "33/33 - 0s - loss: 0.1410 - accuracy: 0.3680 - val_loss: 0.1512 - val_accuracy: 0.3232 - 115ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "33/33 - 0s - loss: 0.1413 - accuracy: 0.4051 - val_loss: 0.1513 - val_accuracy: 0.3004 - 109ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "33/33 - 0s - loss: 0.1413 - accuracy: 0.3508 - val_loss: 0.1516 - val_accuracy: 0.2776 - 103ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "33/33 - 0s - loss: 0.1414 - accuracy: 0.3689 - val_loss: 0.1501 - val_accuracy: 0.3232 - 121ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "33/33 - 0s - loss: 0.1416 - accuracy: 0.3632 - val_loss: 0.1513 - val_accuracy: 0.3574 - 98ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "33/33 - 0s - loss: 0.1413 - accuracy: 0.3651 - val_loss: 0.1523 - val_accuracy: 0.3346 - 94ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "33/33 - 0s - loss: 0.1410 - accuracy: 0.3670 - val_loss: 0.1512 - val_accuracy: 0.3650 - 94ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "33/33 - 0s - loss: 0.1415 - accuracy: 0.3870 - val_loss: 0.1511 - val_accuracy: 0.3156 - 121ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "33/33 - 0s - loss: 0.1406 - accuracy: 0.3746 - val_loss: 0.1522 - val_accuracy: 0.3004 - 100ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "33/33 - 0s - loss: 0.1412 - accuracy: 0.3746 - val_loss: 0.1531 - val_accuracy: 0.3802 - 100ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "33/33 - 0s - loss: 0.1410 - accuracy: 0.3842 - val_loss: 0.1514 - val_accuracy: 0.3156 - 107ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "33/33 - 0s - loss: 0.1406 - accuracy: 0.3575 - val_loss: 0.1508 - val_accuracy: 0.3004 - 111ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "33/33 - 0s - loss: 0.1407 - accuracy: 0.4023 - val_loss: 0.1513 - val_accuracy: 0.3384 - 94ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "33/33 - 0s - loss: 0.1409 - accuracy: 0.3889 - val_loss: 0.1524 - val_accuracy: 0.3574 - 95ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "33/33 - 0s - loss: 0.1414 - accuracy: 0.4051 - val_loss: 0.1521 - val_accuracy: 0.3080 - 109ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "33/33 - 0s - loss: 0.1410 - accuracy: 0.3756 - val_loss: 0.1512 - val_accuracy: 0.3270 - 108ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "33/33 - 0s - loss: 0.1419 - accuracy: 0.3508 - val_loss: 0.1526 - val_accuracy: 0.3346 - 71ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "33/33 - 0s - loss: 0.1413 - accuracy: 0.3651 - val_loss: 0.1514 - val_accuracy: 0.3004 - 102ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "33/33 - 0s - loss: 0.1414 - accuracy: 0.3584 - val_loss: 0.1515 - val_accuracy: 0.3346 - 111ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "33/33 - 0s - loss: 0.1416 - accuracy: 0.3842 - val_loss: 0.1517 - val_accuracy: 0.3536 - 129ms/epoch - 4ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2296cc55870>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'), # 第一隐藏层\n",
        "    tf.keras.layers.Dropout(0.022), # Dropout层\n",
        "    tf.keras.layers.Dense(77, activation='relu'), # 第二隐藏层\n",
        "    tf.keras.layers.Dropout(0.022), # Dropout层\n",
        "    tf.keras.layers.Dense(16, activation='relu'), # 第三隐藏层\n",
        "    tf.keras.layers.Dropout(0.022), # Dropout层\n",
        "    tf.keras.layers.Dense(y_train.shape[1], activation='sigmoid') # 输出层\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0253)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\koyama\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# 训练模\n",
        "\n",
        "# 保存模型\n",
        "model.save('C:/1作品/picture_myclothes/clothesrecommendationmodel.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
