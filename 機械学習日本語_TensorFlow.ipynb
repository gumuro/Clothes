{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import optuna\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをロードします\n",
    "data_full = pd.read_excel('C:/1作品/clothse_excel/train1800.xlsx')\n",
    "\n",
    "# カテゴリー特徴をエンコードします\n",
    "label_encoder = LabelEncoder()\n",
    "data_full['wether'] = label_encoder.fit_transform(data_full['wether'])\n",
    "data_full['season'] = label_encoder.fit_transform(data_full['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\koyama\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 特徴を準備します\n",
    "features = data_full[['max_tem', 'min_tem', 'mean_tem', 'average_humidity', 'average_wind_speed(m/s)', 'sensible_temperature', 'season', 'wether']]\n",
    "\n",
    "# 特徴を標準化します\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# ラベルを準備します\n",
    "labels = data_full[['label1', 'label2', 'label3']]\n",
    "\n",
    "# ラベルをOneHotエンコードします\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "labels_encoded = encoder.fit_transform(labels)\n",
    "\n",
    "# データセットを分割します\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_standardized, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルを構築します\n",
    "def build_model(input_shape, output_units, learning_rate=0.001, dropout_rate=0.25):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(output_units, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 11:37:41,783] A new study created in memory with name: no-name-6317a0fb-ec61-466a-b327-5201fb1844f9\n",
      "C:\\Users\\koyama\\AppData\\Local\\Temp\\ipykernel_9728\\3834844279.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "C:\\Users\\koyama\\AppData\\Local\\Temp\\ipykernel_9728\\3834844279.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "[I 2024-02-13 11:37:45,778] Trial 0 finished with value: 0.1484425663948059 and parameters: {'learning_rate': 0.003122902388408672, 'dropout_rate': 0.3674624353040392}. Best is trial 0 with value: 0.1484425663948059.\n",
      "[I 2024-02-13 11:37:50,294] Trial 1 finished with value: 0.15534457564353943 and parameters: {'learning_rate': 0.00017379618439706648, 'dropout_rate': 0.3501111175193946}. Best is trial 0 with value: 0.1484425663948059.\n",
      "[I 2024-02-13 11:37:54,695] Trial 2 finished with value: 0.14843209087848663 and parameters: {'learning_rate': 0.0034753759060548615, 'dropout_rate': 0.25530860773381703}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:37:58,912] Trial 3 finished with value: 0.15532656013965607 and parameters: {'learning_rate': 0.00014275416708268383, 'dropout_rate': 0.12223142406963144}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:38:02,760] Trial 4 finished with value: 0.14905132353305817 and parameters: {'learning_rate': 0.001150962708898637, 'dropout_rate': 0.12242773226037001}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:38:06,692] Trial 5 finished with value: 0.15733782947063446 and parameters: {'learning_rate': 0.00011265147601067043, 'dropout_rate': 0.13653418741220213}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:38:10,826] Trial 6 finished with value: 0.1561077982187271 and parameters: {'learning_rate': 0.0001324329641664909, 'dropout_rate': 0.15584797870630648}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:38:16,080] Trial 7 finished with value: 0.15136250853538513 and parameters: {'learning_rate': 0.00047048802912964696, 'dropout_rate': 0.35825777072510856}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:38:23,609] Trial 8 finished with value: 0.14863666892051697 and parameters: {'learning_rate': 0.0016113214673039798, 'dropout_rate': 0.24358160036399928}. Best is trial 2 with value: 0.14843209087848663.\n",
      "[I 2024-02-13 11:38:30,927] Trial 9 finished with value: 0.14810247719287872 and parameters: {'learning_rate': 0.0034658138415709348, 'dropout_rate': 0.10875736006256398}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:38:38,010] Trial 10 finished with value: 0.1488722264766693 and parameters: {'learning_rate': 0.006531518600554203, 'dropout_rate': 0.43194910377106854}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:38:45,456] Trial 11 finished with value: 0.1489207148551941 and parameters: {'learning_rate': 0.009108838324360213, 'dropout_rate': 0.23143945296913088}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:38:53,294] Trial 12 finished with value: 0.14858786761760712 and parameters: {'learning_rate': 0.0035128635773333645, 'dropout_rate': 0.21434407811400166}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:01,392] Trial 13 finished with value: 0.14888180792331696 and parameters: {'learning_rate': 0.0029972277803051927, 'dropout_rate': 0.282340290940476}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:09,153] Trial 14 finished with value: 0.14915207028388977 and parameters: {'learning_rate': 0.005497429776192944, 'dropout_rate': 0.17987825310111383}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:16,984] Trial 15 finished with value: 0.1486930251121521 and parameters: {'learning_rate': 0.0019097720996721363, 'dropout_rate': 0.1040250722697882}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:21,424] Trial 16 finished with value: 0.1492520123720169 and parameters: {'learning_rate': 0.0007679128743820797, 'dropout_rate': 0.18805717328286664}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:24,894] Trial 17 finished with value: 0.1487305760383606 and parameters: {'learning_rate': 0.004422721964912166, 'dropout_rate': 0.29157465663768617}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:28,616] Trial 18 finished with value: 0.1491250842809677 and parameters: {'learning_rate': 0.002338795166284688, 'dropout_rate': 0.1759377115595997}. Best is trial 9 with value: 0.14810247719287872.\n",
      "[I 2024-02-13 11:39:34,848] Trial 19 finished with value: 0.1491641104221344 and parameters: {'learning_rate': 0.008940885848095699, 'dropout_rate': 0.24971877501042994}. Best is trial 9 with value: 0.14810247719287872.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適なパラメータ: {'learning_rate': 0.0034658138415709348, 'dropout_rate': 0.10875736006256398}\n"
     ]
    }
   ],
   "source": [
    "# Optunaでハイパーパラメータを最適化します\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "\n",
    "    model = build_model(X_train.shape[1], y_train.shape[1], learning_rate, dropout_rate)\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    history = model.fit(X_train_split, y_train_split, epochs=30, validation_data=(X_val_split, y_val_split), verbose=0, batch_size=32)\n",
    "    \n",
    "    best_loss = min(history.history['val_loss'])\n",
    "    return best_loss\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print('最適なパラメータ:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 2s - loss: 0.2736 - accuracy: 0.2728 - val_loss: 0.1653 - val_accuracy: 0.4167 - 2s/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.1592 - accuracy: 0.3562 - val_loss: 0.1565 - val_accuracy: 0.4028 - 157ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.1535 - accuracy: 0.3475 - val_loss: 0.1556 - val_accuracy: 0.3368 - 203ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.1518 - accuracy: 0.3475 - val_loss: 0.1543 - val_accuracy: 0.3090 - 204ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.1503 - accuracy: 0.3562 - val_loss: 0.1542 - val_accuracy: 0.3576 - 204ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.1484 - accuracy: 0.3328 - val_loss: 0.1537 - val_accuracy: 0.4028 - 200ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.1478 - accuracy: 0.3536 - val_loss: 0.1539 - val_accuracy: 0.3646 - 199ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.1473 - accuracy: 0.3432 - val_loss: 0.1526 - val_accuracy: 0.3611 - 148ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.1459 - accuracy: 0.3475 - val_loss: 0.1525 - val_accuracy: 0.3264 - 211ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.1452 - accuracy: 0.3519 - val_loss: 0.1511 - val_accuracy: 0.3750 - 189ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.1442 - accuracy: 0.3623 - val_loss: 0.1509 - val_accuracy: 0.3194 - 187ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.1446 - accuracy: 0.3440 - val_loss: 0.1513 - val_accuracy: 0.3160 - 220ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.1441 - accuracy: 0.3275 - val_loss: 0.1516 - val_accuracy: 0.3507 - 174ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.1436 - accuracy: 0.3606 - val_loss: 0.1499 - val_accuracy: 0.2986 - 201ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.1437 - accuracy: 0.3423 - val_loss: 0.1504 - val_accuracy: 0.3194 - 189ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.1430 - accuracy: 0.3354 - val_loss: 0.1513 - val_accuracy: 0.3750 - 203ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.1433 - accuracy: 0.3510 - val_loss: 0.1505 - val_accuracy: 0.2847 - 220ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.1425 - accuracy: 0.3545 - val_loss: 0.1502 - val_accuracy: 0.3021 - 225ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.1425 - accuracy: 0.3527 - val_loss: 0.1502 - val_accuracy: 0.3264 - 168ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.1427 - accuracy: 0.3328 - val_loss: 0.1497 - val_accuracy: 0.3368 - 204ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.1422 - accuracy: 0.3519 - val_loss: 0.1502 - val_accuracy: 0.3681 - 211ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.1422 - accuracy: 0.3553 - val_loss: 0.1499 - val_accuracy: 0.3681 - 206ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.1422 - accuracy: 0.3632 - val_loss: 0.1492 - val_accuracy: 0.3021 - 205ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.1414 - accuracy: 0.3354 - val_loss: 0.1488 - val_accuracy: 0.3264 - 138ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.1416 - accuracy: 0.3432 - val_loss: 0.1489 - val_accuracy: 0.3229 - 204ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.1419 - accuracy: 0.3510 - val_loss: 0.1494 - val_accuracy: 0.3229 - 220ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.1415 - accuracy: 0.3449 - val_loss: 0.1492 - val_accuracy: 0.3194 - 148ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.1412 - accuracy: 0.3623 - val_loss: 0.1504 - val_accuracy: 0.3125 - 172ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "36/36 - 0s - loss: 0.1409 - accuracy: 0.3501 - val_loss: 0.1492 - val_accuracy: 0.3611 - 163ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "36/36 - 0s - loss: 0.1407 - accuracy: 0.3553 - val_loss: 0.1493 - val_accuracy: 0.3542 - 139ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "36/36 - 0s - loss: 0.1406 - accuracy: 0.3423 - val_loss: 0.1500 - val_accuracy: 0.3681 - 220ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "36/36 - 0s - loss: 0.1409 - accuracy: 0.3484 - val_loss: 0.1493 - val_accuracy: 0.3611 - 221ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "36/36 - 0s - loss: 0.1409 - accuracy: 0.3684 - val_loss: 0.1500 - val_accuracy: 0.3472 - 204ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "36/36 - 0s - loss: 0.1404 - accuracy: 0.3493 - val_loss: 0.1491 - val_accuracy: 0.3611 - 201ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "36/36 - 0s - loss: 0.1407 - accuracy: 0.3449 - val_loss: 0.1485 - val_accuracy: 0.3472 - 187ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "36/36 - 0s - loss: 0.1404 - accuracy: 0.3458 - val_loss: 0.1487 - val_accuracy: 0.3229 - 161ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "36/36 - 0s - loss: 0.1406 - accuracy: 0.3692 - val_loss: 0.1500 - val_accuracy: 0.3229 - 206ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "36/36 - 0s - loss: 0.1405 - accuracy: 0.3545 - val_loss: 0.1495 - val_accuracy: 0.3403 - 176ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "36/36 - 0s - loss: 0.1405 - accuracy: 0.3493 - val_loss: 0.1491 - val_accuracy: 0.3021 - 205ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "36/36 - 0s - loss: 0.1405 - accuracy: 0.3545 - val_loss: 0.1487 - val_accuracy: 0.3403 - 205ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "36/36 - 0s - loss: 0.1405 - accuracy: 0.3449 - val_loss: 0.1485 - val_accuracy: 0.3333 - 170ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "36/36 - 0s - loss: 0.1399 - accuracy: 0.3414 - val_loss: 0.1490 - val_accuracy: 0.3264 - 204ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "36/36 - 0s - loss: 0.1399 - accuracy: 0.3545 - val_loss: 0.1486 - val_accuracy: 0.3542 - 206ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "36/36 - 0s - loss: 0.1396 - accuracy: 0.3632 - val_loss: 0.1488 - val_accuracy: 0.3438 - 202ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "36/36 - 0s - loss: 0.1400 - accuracy: 0.3640 - val_loss: 0.1491 - val_accuracy: 0.3229 - 221ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "36/36 - 0s - loss: 0.1400 - accuracy: 0.3493 - val_loss: 0.1487 - val_accuracy: 0.3229 - 201ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "36/36 - 0s - loss: 0.1397 - accuracy: 0.3440 - val_loss: 0.1479 - val_accuracy: 0.3229 - 173ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "36/36 - 0s - loss: 0.1391 - accuracy: 0.3328 - val_loss: 0.1493 - val_accuracy: 0.3542 - 206ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "36/36 - 0s - loss: 0.1403 - accuracy: 0.3536 - val_loss: 0.1481 - val_accuracy: 0.3438 - 199ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "36/36 - 0s - loss: 0.1394 - accuracy: 0.3692 - val_loss: 0.1484 - val_accuracy: 0.3125 - 204ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "36/36 - 0s - loss: 0.1400 - accuracy: 0.3440 - val_loss: 0.1489 - val_accuracy: 0.3611 - 213ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "36/36 - 0s - loss: 0.1392 - accuracy: 0.3675 - val_loss: 0.1496 - val_accuracy: 0.3611 - 173ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "36/36 - 0s - loss: 0.1399 - accuracy: 0.3467 - val_loss: 0.1496 - val_accuracy: 0.3229 - 188ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "36/36 - 0s - loss: 0.1394 - accuracy: 0.3606 - val_loss: 0.1493 - val_accuracy: 0.3090 - 202ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "36/36 - 0s - loss: 0.1396 - accuracy: 0.3449 - val_loss: 0.1484 - val_accuracy: 0.3611 - 220ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "36/36 - 0s - loss: 0.1392 - accuracy: 0.3449 - val_loss: 0.1485 - val_accuracy: 0.3229 - 204ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "36/36 - 0s - loss: 0.1389 - accuracy: 0.3414 - val_loss: 0.1486 - val_accuracy: 0.2812 - 196ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "36/36 - 0s - loss: 0.1390 - accuracy: 0.3727 - val_loss: 0.1485 - val_accuracy: 0.3229 - 181ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "36/36 - 0s - loss: 0.1392 - accuracy: 0.3258 - val_loss: 0.1489 - val_accuracy: 0.3299 - 141ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "36/36 - 0s - loss: 0.1390 - accuracy: 0.3623 - val_loss: 0.1492 - val_accuracy: 0.3125 - 158ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "36/36 - 0s - loss: 0.1391 - accuracy: 0.3510 - val_loss: 0.1497 - val_accuracy: 0.3438 - 204ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "36/36 - 0s - loss: 0.1389 - accuracy: 0.3493 - val_loss: 0.1492 - val_accuracy: 0.3194 - 202ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "36/36 - 0s - loss: 0.1392 - accuracy: 0.3788 - val_loss: 0.1481 - val_accuracy: 0.3438 - 205ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "36/36 - 0s - loss: 0.1394 - accuracy: 0.3597 - val_loss: 0.1484 - val_accuracy: 0.3090 - 142ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "36/36 - 0s - loss: 0.1390 - accuracy: 0.3406 - val_loss: 0.1489 - val_accuracy: 0.3160 - 182ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "36/36 - 0s - loss: 0.1387 - accuracy: 0.3432 - val_loss: 0.1485 - val_accuracy: 0.3681 - 204ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "36/36 - 0s - loss: 0.1390 - accuracy: 0.3458 - val_loss: 0.1480 - val_accuracy: 0.2917 - 221ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "36/36 - 0s - loss: 0.1391 - accuracy: 0.3719 - val_loss: 0.1477 - val_accuracy: 0.3333 - 186ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "36/36 - 0s - loss: 0.1390 - accuracy: 0.3458 - val_loss: 0.1484 - val_accuracy: 0.3681 - 158ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3484 - val_loss: 0.1484 - val_accuracy: 0.3438 - 198ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3632 - val_loss: 0.1487 - val_accuracy: 0.3611 - 204ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "36/36 - 0s - loss: 0.1385 - accuracy: 0.3527 - val_loss: 0.1497 - val_accuracy: 0.3125 - 220ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3414 - val_loss: 0.1482 - val_accuracy: 0.3333 - 204ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3701 - val_loss: 0.1486 - val_accuracy: 0.3125 - 205ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3336 - val_loss: 0.1484 - val_accuracy: 0.3299 - 159ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3519 - val_loss: 0.1484 - val_accuracy: 0.3438 - 138ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "36/36 - 0s - loss: 0.1384 - accuracy: 0.3527 - val_loss: 0.1483 - val_accuracy: 0.3229 - 188ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "36/36 - 0s - loss: 0.1392 - accuracy: 0.3536 - val_loss: 0.1483 - val_accuracy: 0.2917 - 117ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3510 - val_loss: 0.1479 - val_accuracy: 0.3229 - 142ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "36/36 - 0s - loss: 0.1385 - accuracy: 0.3371 - val_loss: 0.1485 - val_accuracy: 0.3507 - 123ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "36/36 - 0s - loss: 0.1380 - accuracy: 0.3458 - val_loss: 0.1483 - val_accuracy: 0.3333 - 133ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "36/36 - 0s - loss: 0.1383 - accuracy: 0.3658 - val_loss: 0.1479 - val_accuracy: 0.3125 - 133ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "36/36 - 0s - loss: 0.1379 - accuracy: 0.3397 - val_loss: 0.1488 - val_accuracy: 0.3299 - 144ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3536 - val_loss: 0.1492 - val_accuracy: 0.3229 - 102ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "36/36 - 0s - loss: 0.1388 - accuracy: 0.3527 - val_loss: 0.1481 - val_accuracy: 0.3333 - 158ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "36/36 - 0s - loss: 0.1383 - accuracy: 0.3510 - val_loss: 0.1484 - val_accuracy: 0.3507 - 151ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "36/36 - 0s - loss: 0.1385 - accuracy: 0.3519 - val_loss: 0.1485 - val_accuracy: 0.3403 - 132ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "36/36 - 0s - loss: 0.1385 - accuracy: 0.3371 - val_loss: 0.1484 - val_accuracy: 0.3125 - 167ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "36/36 - 0s - loss: 0.1380 - accuracy: 0.3371 - val_loss: 0.1486 - val_accuracy: 0.3229 - 150ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "36/36 - 0s - loss: 0.1384 - accuracy: 0.3371 - val_loss: 0.1482 - val_accuracy: 0.2917 - 142ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "36/36 - 0s - loss: 0.1388 - accuracy: 0.3458 - val_loss: 0.1479 - val_accuracy: 0.3125 - 198ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "36/36 - 0s - loss: 0.1382 - accuracy: 0.3397 - val_loss: 0.1488 - val_accuracy: 0.3160 - 160ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "36/36 - 0s - loss: 0.1385 - accuracy: 0.3579 - val_loss: 0.1483 - val_accuracy: 0.3125 - 174ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "36/36 - 0s - loss: 0.1382 - accuracy: 0.3484 - val_loss: 0.1484 - val_accuracy: 0.3333 - 183ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "36/36 - 0s - loss: 0.1380 - accuracy: 0.3501 - val_loss: 0.1485 - val_accuracy: 0.3507 - 204ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "36/36 - 0s - loss: 0.1381 - accuracy: 0.3597 - val_loss: 0.1486 - val_accuracy: 0.3299 - 162ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "36/36 - 0s - loss: 0.1386 - accuracy: 0.3562 - val_loss: 0.1483 - val_accuracy: 0.3299 - 209ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "36/36 - 0s - loss: 0.1383 - accuracy: 0.3527 - val_loss: 0.1488 - val_accuracy: 0.2917 - 196ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "36/36 - 0s - loss: 0.1382 - accuracy: 0.3536 - val_loss: 0.1481 - val_accuracy: 0.2986 - 165ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "36/36 - 0s - loss: 0.1381 - accuracy: 0.3536 - val_loss: 0.1485 - val_accuracy: 0.3333 - 181ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 最適なパラメータでモデルを訓練します\n",
    "model = build_model(X_train.shape[1], y_train.shape[1], best_params['learning_rate'], best_params['dropout_rate'])\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.1430 - accuracy: 0.3556 - 215ms/epoch - 18ms/step\n",
      "テスト精度: 0.35555556416511536, テスト損失: 0.1429639756679535\n"
     ]
    }
   ],
   "source": [
    "# モデルを評価します\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'テスト精度: {test_acc}, テスト損失: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step\n",
      "ラベル 0 の混同行列:\n",
      "[[356   0]\n",
      " [  4   0]]\n",
      "\n",
      "ラベル 1 の混同行列:\n",
      "[[195  15]\n",
      " [ 44 106]]\n",
      "\n",
      "ラベル 2 の混同行列:\n",
      "[[310   0]\n",
      " [ 50   0]]\n",
      "\n",
      "ラベル 3 の混同行列:\n",
      "[[350   0]\n",
      " [ 10   0]]\n",
      "\n",
      "ラベル 4 の混同行列:\n",
      "[[311   7]\n",
      " [ 31  11]]\n",
      "\n",
      "ラベル 5 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 6 の混同行列:\n",
      "[[348   0]\n",
      " [ 12   0]]\n",
      "\n",
      "ラベル 7 の混同行列:\n",
      "[[350   0]\n",
      " [ 10   0]]\n",
      "\n",
      "ラベル 8 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 9 の混同行列:\n",
      "[[346   0]\n",
      " [ 14   0]]\n",
      "\n",
      "ラベル 10 の混同行列:\n",
      "[[338   0]\n",
      " [ 22   0]]\n",
      "\n",
      "ラベル 11 の混同行列:\n",
      "[[354   0]\n",
      " [  6   0]]\n",
      "\n",
      "ラベル 12 の混同行列:\n",
      "[[358   0]\n",
      " [  2   0]]\n",
      "\n",
      "ラベル 13 の混同行列:\n",
      "[[359   0]\n",
      " [  1   0]]\n",
      "\n",
      "ラベル 14 の混同行列:\n",
      "[[345   0]\n",
      " [ 15   0]]\n",
      "\n",
      "ラベル 15 の混同行列:\n",
      "[[359   0]\n",
      " [  1   0]]\n",
      "\n",
      "ラベル 16 の混同行列:\n",
      "[[359   0]\n",
      " [  1   0]]\n",
      "\n",
      "ラベル 17 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 18 の混同行列:\n",
      "[[340   0]\n",
      " [ 20   0]]\n",
      "\n",
      "ラベル 19 の混同行列:\n",
      "[[322   0]\n",
      " [ 38   0]]\n",
      "\n",
      "ラベル 20 の混同行列:\n",
      "[[328   0]\n",
      " [ 32   0]]\n",
      "\n",
      "ラベル 21 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 22 の混同行列:\n",
      "[[335   0]\n",
      " [ 25   0]]\n",
      "\n",
      "ラベル 23 の混同行列:\n",
      "[[359   0]\n",
      " [  1   0]]\n",
      "\n",
      "ラベル 24 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 25 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 26 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 27 の混同行列:\n",
      "[[359   0]\n",
      " [  1   0]]\n",
      "\n",
      "ラベル 28 の混同行列:\n",
      "[[278   3]\n",
      " [ 67  12]]\n",
      "\n",
      "ラベル 29 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 30 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 31 の混同行列:\n",
      "[[357   0]\n",
      " [  3   0]]\n",
      "\n",
      "ラベル 32 の混同行列:\n",
      "[[289  14]\n",
      " [ 45  12]]\n",
      "\n",
      "ラベル 33 の混同行列:\n",
      "[[253  18]\n",
      " [ 63  26]]\n",
      "\n",
      "ラベル 34 の混同行列:\n",
      "[[345   0]\n",
      " [ 15   0]]\n",
      "\n",
      "ラベル 35 の混同行列:\n",
      "[[360   0]\n",
      " [  0   0]]\n",
      "\n",
      "ラベル 36 の混同行列:\n",
      "[[340   0]\n",
      " [ 20   0]]\n",
      "\n",
      "ラベル 37 の混同行列:\n",
      "[[345   0]\n",
      " [ 15   0]]\n",
      "\n",
      "ラベル 38 の混同行列:\n",
      "[[198  44]\n",
      " [ 85  33]]\n",
      "\n",
      "ラベル 39 の混同行列:\n",
      "[[349   0]\n",
      " [ 11   0]]\n",
      "\n",
      "ラベル 40 の混同行列:\n",
      "[[358   0]\n",
      " [  2   0]]\n",
      "\n",
      "ラベル 41 の混同行列:\n",
      "[[328   0]\n",
      " [ 32   0]]\n",
      "\n",
      "ラベル 42 の混同行列:\n",
      "[[339   0]\n",
      " [ 21   0]]\n",
      "\n",
      "ラベル 43 の混同行列:\n",
      "[[223  25]\n",
      " [ 90  22]]\n",
      "\n",
      "ラベル 44 の混同行列:\n",
      "[[345   0]\n",
      " [ 15   0]]\n",
      "\n",
      "ラベル 45 の混同行列:\n",
      "[[344   0]\n",
      " [ 16   0]]\n",
      "\n",
      "ラベル 46 の混同行列:\n",
      "[[353   0]\n",
      " [  7   0]]\n",
      "\n",
      "ラベル 47 の混同行列:\n",
      "[[350   0]\n",
      " [ 10   0]]\n",
      "\n",
      "ラベル 48 の混同行列:\n",
      "[[359   0]\n",
      " [  1   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# マルチラベル混同行列を計算します\n",
    "y_pred = model.predict(X_test) > 0.5\n",
    "confusion_matrices = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "for i, matrix in enumerate(confusion_matrices):\n",
    "    print(f\"ラベル {i} の混同行列:\\n{matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全体の混同行列:\n",
      "[[16434   126]\n",
      " [  858   222]]\n"
     ]
    }
   ],
   "source": [
    "# 全体の混同行列を計算します\n",
    "y_test_flattened = y_test.flatten()\n",
    "y_pred_flattened = y_pred.flatten()\n",
    "conf_matrix = confusion_matrix(y_test_flattened, y_pred_flattened)\n",
    "print(\"全体の混同行列:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全体の精度: 0.013888888888888888\n",
      "Hoodie の正確さ: 0.9888888888888889\n",
      "Unknown の正確さ: 0.8361111111111111\n",
      "coat の正確さ: 0.8611111111111112\n",
      "denim jacket の正確さ: 0.9722222222222222\n",
      "jackets の正確さ: 0.8944444444444445\n",
      "jeans の正確さ: 1.0\n",
      "knitted coat の正確さ: 0.9666666666666667\n",
      "long down jacket の正確さ: 0.9722222222222222\n",
      "long-sleeved dress の正確さ: 1.0\n",
      "shirts の正確さ: 0.9611111111111111\n",
      "short down jacket の正確さ: 0.9388888888888889\n",
      "short trench coat の正確さ: 0.9833333333333333\n",
      "short woolen coat の正確さ: 0.9944444444444445\n",
      "shorts の正確さ: 0.9972222222222222\n",
      "suit jackets の正確さ: 0.9583333333333334\n",
      "sweater の正確さ: 0.9972222222222222\n",
      "t-shirts の正確さ: 0.9972222222222222\n",
      "vest の正確さ: 1.0\n",
      "windbreaker の正確さ: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# 全体の精度を計算します\n",
    "y_pred_binary = (y_pred > 0.5)\n",
    "overall_accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f\"全体の精度: {overall_accuracy}\")\n",
    "\n",
    "# 各ラベルの正確さを計算します\n",
    "for i, label in enumerate(encoder.categories_[0]):\n",
    "    label_accuracy = accuracy_score(y_test[:, i], y_pred_binary[:, i])\n",
    "    print(f\"{label} の正確さ: {label_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\koyama\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 指定的模型保存路径，确保以.h5结尾\n",
    "model_path = 'C:/1作品/picture_myclothes/my_model.h5'\n",
    "\n",
    "# 获取目录路径\n",
    "directory = os.path.dirname(model_path)\n",
    "\n",
    "# 如果目录不存在，则创建它\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# 现在可以安全地保存模型了\n",
    "model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
